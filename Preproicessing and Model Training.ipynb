{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_dataframe(main_data):\n",
    "    #load all aditional dataframes\n",
    "    oil_data = pd.read_csv(\"./Data/oil.csv\", parse_dates= [\"date\"])\n",
    "    holiday_data = pd.read_csv(\"./Data/holidays_events.csv\", parse_dates= [\"date\"])\n",
    "    stores_data = pd.read_csv(\"./Data/stores.csv\")\n",
    "    trans_data = pd.read_csv(\"./Data/transactions.csv\", parse_dates= ['date'])\n",
    "\n",
    "    # preprocess dataframes: updating datatypes and filling missing values\n",
    "\n",
    "    main_datatype = {\"store_nbr\": \"category\", \"family\" :\"category\"}\n",
    "    main_data = main_data.astype(main_datatype)\n",
    "\n",
    "    oil_data.fillna(method = \"backfill\", inplace = True)\n",
    "\n",
    "    holiday_datatypes = {\"type\": \"category\",\"locale\":\"category\", \"locale_name\": \"category\", \"description\": \"string\"}\n",
    "    holiday_data = holiday_data.astype(holiday_datatypes)\n",
    "\n",
    "    stores_data = stores_data.astype(\"category\")\n",
    "\n",
    "    # split holiday dataframe based on holiday types\n",
    "    holiday_local  = holiday_data[holiday_data[\"locale\"]== \"Local\"].copy()\n",
    "    holiday_local.rename(columns={'locale_name': 'city'}, inplace=True)\n",
    "    holiday_local= holiday_local.drop_duplicates(subset=['date', 'city'])\n",
    "    holiday_regional  = holiday_data[holiday_data[\"locale\"]== \"Regional\"].copy()\n",
    "    holiday_regional.rename(columns={'locale_name': 'state'}, inplace=True)\n",
    "    holiday_regional= holiday_regional.drop_duplicates(subset=['date', 'state'])\n",
    "    holiday_national = holiday_data[holiday_data[\"locale\"]== \"National\"].copy()\n",
    "    holiday_national= holiday_national.drop_duplicates(subset=['date'])\n",
    "\n",
    "    # merging all frames to create the final dataframe: \n",
    "    df = main_data.merge(oil_data, on = \"date\", how = \"left\").fillna(method = 'ffill')\n",
    "    df = df.merge(stores_data, on = \"store_nbr\", how = \"left\", )\n",
    "    df = df.merge(trans_data, on = [\"date\", \"store_nbr\"], how = \"left\")\n",
    "    df = df.merge(holiday_local, on = [\"date\", \"city\"], how = \"left\", suffixes= (\"_store\", \"_holiday\")) \n",
    "    df = df.merge(holiday_regional, on = [\"date\", \"state\"], how = \"left\",)\n",
    "    df = df.merge(holiday_national, on =\"date\", how = \"left\")\n",
    "    \n",
    "    # Filing missing values of type holiday variable in the df dataframe\n",
    "    type_holiday = df['type_holiday'].combine_first(df['type_x']).combine_first(df['type_y'])\n",
    "    locale = df['locale_x'].combine_first(df['locale_y']).combine_first(df['locale'])\n",
    "    transferred =  df['transferred_x'].combine_first(df['transferred_y']).combine_first(df['transferred'])\n",
    "    \n",
    "    # create the final version of df dataframe by adding the correct columns of holiday dataframe\n",
    "    df = df.iloc[:, :11]\n",
    "    df['type_holiday']= type_holiday\n",
    "    df['locale']= locale\n",
    "    df['transferred'] = transferred\n",
    "\n",
    "    # trim the final dataframe by improving its columns' datatypes and imputing the missing values\n",
    "    df['type_holiday'] = df['type_holiday'].cat.add_categories(\"IsNotHoliday\")  \n",
    "    df['locale'] = df['locale'].cat.add_categories(\"IsNotHoliday\") \n",
    "\n",
    "    fill_values = {\"type_holiday\" :\"IsNotHoliday\", \"locale\":\"IsNotHoliday\"}\n",
    "    df.fillna(fill_values, inplace = True)\n",
    "\n",
    "    df.fillna({\"transferred\": False, \"transactions\": 0}, inplace = True)\n",
    "\n",
    "    df = df.astype({\"city\":\"category\", \"state\": \"category\"})\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_11136\\2714224997.py:52: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.fillna(fill_values, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type_store</th>\n",
       "      <th>cluster</th>\n",
       "      <th>type_holiday</th>\n",
       "      <th>locale</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008275</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>POULTRY</td>\n",
       "      <td>438.133</td>\n",
       "      <td>0</td>\n",
       "      <td>47.57</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>IsNotHoliday</td>\n",
       "      <td>IsNotHoliday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008276</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>154.553</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>IsNotHoliday</td>\n",
       "      <td>IsNotHoliday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008277</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>2419.729</td>\n",
       "      <td>148</td>\n",
       "      <td>47.57</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>IsNotHoliday</td>\n",
       "      <td>IsNotHoliday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008278</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>121.000</td>\n",
       "      <td>8</td>\n",
       "      <td>47.57</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>IsNotHoliday</td>\n",
       "      <td>IsNotHoliday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008279</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0</td>\n",
       "      <td>47.57</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>IsNotHoliday</td>\n",
       "      <td>IsNotHoliday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3008280 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date store_nbr                      family     sales  \\\n",
       "0       2013-01-01         1                  AUTOMOTIVE     0.000   \n",
       "1       2013-01-01         1                   BABY CARE     0.000   \n",
       "2       2013-01-01         1                      BEAUTY     0.000   \n",
       "3       2013-01-01         1                   BEVERAGES     0.000   \n",
       "4       2013-01-01         1                       BOOKS     0.000   \n",
       "...            ...       ...                         ...       ...   \n",
       "3008275 2017-08-15         9                     POULTRY   438.133   \n",
       "3008276 2017-08-15         9              PREPARED FOODS   154.553   \n",
       "3008277 2017-08-15         9                     PRODUCE  2419.729   \n",
       "3008278 2017-08-15         9  SCHOOL AND OFFICE SUPPLIES   121.000   \n",
       "3008279 2017-08-15         9                     SEAFOOD    16.000   \n",
       "\n",
       "         onpromotion  dcoilwtico   city      state type_store cluster  \\\n",
       "0                  0       93.14  Quito  Pichincha          D      13   \n",
       "1                  0       93.14  Quito  Pichincha          D      13   \n",
       "2                  0       93.14  Quito  Pichincha          D      13   \n",
       "3                  0       93.14  Quito  Pichincha          D      13   \n",
       "4                  0       93.14  Quito  Pichincha          D      13   \n",
       "...              ...         ...    ...        ...        ...     ...   \n",
       "3008275            0       47.57  Quito  Pichincha          B       6   \n",
       "3008276            1       47.57  Quito  Pichincha          B       6   \n",
       "3008277          148       47.57  Quito  Pichincha          B       6   \n",
       "3008278            8       47.57  Quito  Pichincha          B       6   \n",
       "3008279            0       47.57  Quito  Pichincha          B       6   \n",
       "\n",
       "         type_holiday        locale  transferred  \n",
       "0             Holiday      National        False  \n",
       "1             Holiday      National        False  \n",
       "2             Holiday      National        False  \n",
       "3             Holiday      National        False  \n",
       "4             Holiday      National        False  \n",
       "...               ...           ...          ...  \n",
       "3008275  IsNotHoliday  IsNotHoliday        False  \n",
       "3008276  IsNotHoliday  IsNotHoliday        False  \n",
       "3008277  IsNotHoliday  IsNotHoliday        False  \n",
       "3008278  IsNotHoliday  IsNotHoliday        False  \n",
       "3008279  IsNotHoliday  IsNotHoliday        False  \n",
       "\n",
       "[3008280 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./Data/train.csv\", parse_dates = ['date'] ,  index_col='id')\n",
    "\n",
    "df = create_final_dataframe(train_data)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_11136\\2714224997.py:52: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.fillna(fill_values, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type_store</th>\n",
       "      <th>cluster</th>\n",
       "      <th>type_holiday</th>\n",
       "      <th>locale</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>IsNotHoliday</td>\n",
       "      <td>IsNotHoliday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store_nbr      family  onpromotion  dcoilwtico   city  \\\n",
       "0 2017-08-16          1  AUTOMOTIVE            0        46.8  Quito   \n",
       "\n",
       "       state type_store cluster  type_holiday        locale  transferred  \n",
       "0  Pichincha          D      13  IsNotHoliday  IsNotHoliday        False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"./Data/test.csv\",  index_col='id', parse_dates = ['date'] )\n",
    "test_frame = create_final_dataframe(test_data.iloc[:1, :])\n",
    "\n",
    "test_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new time features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_vars(dataframe):\n",
    "    dataframe['year'] = dataframe[\"date\"].apply(lambda x: x.year)\n",
    "    dataframe['month'] = dataframe[\"date\"].apply(lambda x: x.month)\n",
    "    dataframe['day'] = dataframe[\"date\"].apply(lambda x : x.day)\n",
    "    dataframe['dayweek'] = dataframe[\"date\"].apply(lambda x : x.day_name()).astype(\"category\")\n",
    "    dataframe[\"quarter\"] = dataframe[\"date\"].apply(lambda x: x.quarter)\n",
    "    dataframe[\"weekyear\"]= dataframe[\"date\"].apply(lambda x: x.weekofyear).astype(bool)\n",
    "    dataframe[\"isweekend\"] = dataframe[\"date\"].dt.dayofweek // 5 \n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3008280 entries, 0 to 3008279\n",
      "Data columns (total 20 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   date          datetime64[ns]\n",
      " 1   store_nbr     category      \n",
      " 2   family        category      \n",
      " 3   sales         float64       \n",
      " 4   onpromotion   int64         \n",
      " 5   dcoilwtico    float64       \n",
      " 6   city          category      \n",
      " 7   state         category      \n",
      " 8   type_store    category      \n",
      " 9   cluster       category      \n",
      " 10  type_holiday  category      \n",
      " 11  locale        category      \n",
      " 12  transferred   bool          \n",
      " 13  year          int64         \n",
      " 14  month         int64         \n",
      " 15  day           int64         \n",
      " 16  dayweek       category      \n",
      " 17  quarter       int64         \n",
      " 18  weekyear      bool          \n",
      " 19  isweekend     int64         \n",
      "dtypes: bool(2), category(9), datetime64[ns](1), float64(2), int64(6)\n",
      "memory usage: 261.1 MB\n"
     ]
    }
   ],
   "source": [
    "df = extract_time_vars(df)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(model):\n",
    "    train_performance = []\n",
    "    test_performance = []\n",
    "\n",
    "    y_hat_train = np.exp(model.predict(X_train))-10\n",
    "    y_hat_test = np.exp(model.predict(X_test))-10\n",
    "\n",
    "    y_hat_train[y_hat_train <0] = 0\n",
    "    y_hat_test[y_hat_test<0] = 0\n",
    "\n",
    "\n",
    "    train_performance.append(np.sqrt(mean_squared_error(y_train, y_hat_train)))\n",
    "    test_performance.append(np.sqrt(mean_squared_error(y_test, y_hat_test)))\n",
    "\n",
    "    train_performance.append(mean_absolute_error(y_train, y_hat_train))\n",
    "    test_performance.append(mean_absolute_error(y_test, y_hat_test))\n",
    "\n",
    "    train_performance.append(mean_squared_log_error(y_train, y_hat_train, squared= False))\n",
    "    test_performance.append(mean_squared_log_error(y_test, y_hat_test, squared= False))\n",
    "\n",
    "    train_performance.append(r2_score(y_train, y_hat_train))\n",
    "    test_performance.append(r2_score(y_test, y_hat_test))\n",
    "\n",
    "\n",
    "    df_performance = pd.DataFrame([train_performance,test_performance], columns=['mean_squared_error', 'mean_absolute_error', 'RMSLE', 'r2_score'], index= ['trian','test'])\n",
    "    display(df_performance)\n",
    "\n",
    "    fig ,ax = plt.subplots(1,2, figsize = (10,4))\n",
    "    sns.scatterplot(x = y_train, y = y_hat_train, ax = ax[0])\n",
    "    ax[0].set_xlabel(\"y_real\")\n",
    "    ax[0].set_ylabel(\"y_prediction\")\n",
    "    ax[0].set_title(\"Train\")\n",
    "    ax[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--')\n",
    "\n",
    "    sns.scatterplot(x = y_test, y = y_hat_test, ax = ax[1])\n",
    "    ax[1].set_xlabel(\"y_real\")\n",
    "    ax[1].set_ylabel(\"y_prediction\")\n",
    "    ax[1].set_title(\"Test\")\n",
    "    ax[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.show()\n",
    "\n",
    "    return train_performance, test_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write code based on functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error\n",
    "\n",
    "# Define your variables\n",
    "cont_vars = [ 'onpromotion', 'dcoilwtico']\n",
    "encode_vars = ['store_nbr', 'city', 'state', 'type_store','cluster','type_holiday', 'locale', 'dayweek']\n",
    "other_vars = ['year','month', 'day', 'quarter' , 'weekyear', 'isweekend', 'transferred']\n",
    "cols = cont_vars +encode_vars + other_vars\n",
    "categories = list(df['family'].unique())\n",
    "\n",
    "\n",
    "def preprocess_train_v01(model, split_date = \"2017-01-01\"):\n",
    "\n",
    "    split_date = pd.to_datetime(split_date) \n",
    "    # Split the data\n",
    "    train_data = df[df.date< split_date]\n",
    "    test_data = df[df.date >= split_date]\n",
    "    y_hat_test_all = pd.Series(index=test_data.index) \n",
    "\n",
    "    # Create the preprocessing pipeline, we need to use the ColumnTransfer class since each transforemer will be applied on diffrent part of dataframe\n",
    "    ct = ColumnTransformer(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler(), cont_vars),\n",
    "            (\"onehot_encoder\", OneHotEncoder(), encode_vars)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Create the main pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', ct),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    print(\"RMSLE within each category\\n\", \"=\"*(50))\n",
    "    for cat in categories:\n",
    "        X_train = train_data[train_data['family']==cat][cols]\n",
    "        X_test = test_data[test_data['family']==cat][cols]\n",
    "        y_train = train_data[train_data['family']==cat]['sales']\n",
    "        y_test = test_data[test_data['family']==cat]['sales']\n",
    "        y_train_log = np.log(y_train+10)\n",
    "        y_test_log = np.log(y_test+10)\n",
    "\n",
    "        pipeline.fit(X_train, y_train_log)\n",
    "        y_hat_test = np.exp(pipeline.predict(X_test))-10\n",
    "        y_hat_test[y_hat_test<0] = 0\n",
    "        print(f\"{cat}:\", \" \"*(30-len(cat)), mean_squared_log_error(y_test, y_hat_test, squared= False))\n",
    "\n",
    "        y_hat_test_all[test_data.index[test_data['family'] == cat]] = y_hat_test\n",
    "\n",
    "    \n",
    "    # Calculate the MSLE for all categories combined\n",
    "    overall_rmsle = mean_squared_log_error(test_data['sales'], y_hat_test_all, squared= False)\n",
    "    print(\"=\"*(50))\n",
    "    print(\"Overall RMSLE:\", \" \"*(30-len(\"Overall RMSLE\")), overall_rmsle)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode time features\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error\n",
    "\n",
    "# Define your variables\n",
    "cont_vars = [ 'onpromotion', 'dcoilwtico']\n",
    "encode_vars = ['store_nbr', 'city', 'state', 'type_store','cluster','type_holiday', 'locale', 'dayweek', 'year','month', 'day', 'quarter' , 'weekyear',]\n",
    "other_vars = [ 'isweekend', 'transferred']\n",
    "cols = cont_vars + encode_vars + other_vars\n",
    "categories = list(df['family'].unique())\n",
    "\n",
    "\n",
    "def preprocess_train_v02(model, split_date = \"2017-01-01\"):\n",
    "\n",
    "    split_date = pd.to_datetime(split_date) \n",
    "    # Split the data\n",
    "    train_data = df[df.date< split_date]\n",
    "    test_data = df[df.date >= split_date]\n",
    "    y_hat_test_all = pd.Series(index=test_data.index) \n",
    "\n",
    "    # Create the preprocessing pipeline, we need to use the ColumnTransfer class since each transforemer will be applied on diffrent part of dataframe\n",
    "    ct = ColumnTransformer(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler(), cont_vars),\n",
    "            (\"onehot_encoder\", OneHotEncoder(handle_unknown= 'infrequent_if_exist', min_frequency= 0.005), encode_vars)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Create the main pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', ct),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    print(\"RMSLE within each category\\n\", \"=\"*(50))\n",
    "    for cat in categories:\n",
    "        X_train = train_data[train_data['family']==cat][cols]\n",
    "        X_test = test_data[test_data['family']==cat][cols]\n",
    "        y_train = train_data[train_data['family']==cat]['sales']\n",
    "        y_test = test_data[test_data['family']==cat]['sales']\n",
    "        y_train_log = np.log(y_train+10)\n",
    "        y_test_log = np.log(y_test+10)\n",
    "\n",
    "        pipeline.fit(X_train, y_train_log)\n",
    "        y_hat_test = np.exp(pipeline.predict(X_test))-10\n",
    "        y_hat_test[y_hat_test<0] = 0\n",
    "        print(f\"{cat}:\", \" \"*(30-len(cat)), mean_squared_log_error(y_test, y_hat_test, squared= False))\n",
    "\n",
    "        y_hat_test_all[test_data.index[test_data['family'] == cat]] = y_hat_test\n",
    "\n",
    "    \n",
    "    # Calculate the MSLE for all categories combined\n",
    "    overall_rmsle = mean_squared_log_error(test_data['sales'], y_hat_test_all, squared= False)\n",
    "    print(\"=\"*(50))\n",
    "    print(\"Overall RMSLE:\", \" \"*(30-len(\"Overall RMSLE\")), overall_rmsle)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace onehot encoding with target encoding\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, TargetEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error\n",
    "\n",
    "# Define your variables\n",
    "cont_vars = [ 'onpromotion', 'dcoilwtico']\n",
    "encode_vars = ['store_nbr', 'city', 'state', 'type_store','cluster','type_holiday', 'locale', 'dayweek']\n",
    "other_vars = ['year','month', 'day', 'quarter' , 'weekyear', 'isweekend', 'transferred']\n",
    "cols = cont_vars +encode_vars + other_vars\n",
    "categories = list(df['family'].unique())\n",
    "\n",
    "\n",
    "def preprocess_train_v03(model, split_date = \"2017-01-01\"):\n",
    "\n",
    "    split_date = pd.to_datetime(split_date) \n",
    "    # Split the data\n",
    "    train_data = df[df.date< split_date]\n",
    "    test_data = df[df.date >= split_date]\n",
    "    y_hat_test_all = pd.Series(index=test_data.index) \n",
    "\n",
    "    # Create the preprocessing pipeline, we need to use the ColumnTransfer class since each transforemer will be applied on diffrent part of dataframe\n",
    "    ct = ColumnTransformer(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler(), cont_vars),\n",
    "            (\"onehot_encoder\", TargetEncoder(), encode_vars)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Create the main pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', ct),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    print(\"RMSLE within each category\\n\", \"=\"*(50))\n",
    "    for cat in categories:\n",
    "        X_train = train_data[train_data['family']==cat][cols]\n",
    "        X_test = test_data[test_data['family']==cat][cols]\n",
    "        y_train = train_data[train_data['family']==cat]['sales']\n",
    "        y_test = test_data[test_data['family']==cat]['sales']\n",
    "        y_train_log = np.log(y_train+10)\n",
    "        y_test_log = np.log(y_test+10)\n",
    "\n",
    "        pipeline.fit(X_train, y_train_log)\n",
    "        y_hat_test = np.exp(pipeline.predict(X_test))-10\n",
    "        y_hat_test[y_hat_test<0] = 0\n",
    "        print(f\"{cat}:\", \" \"*(30-len(cat)), mean_squared_log_error(y_test, y_hat_test, squared= False))\n",
    "\n",
    "        y_hat_test_all[test_data.index[test_data['family'] == cat]] = y_hat_test\n",
    "\n",
    "    \n",
    "    # Calculate the MSLE for all categories combined\n",
    "    overall_rmsle = mean_squared_log_error(test_data['sales'], y_hat_test_all, squared= False)\n",
    "    print(\"=\"*(50))\n",
    "    print(\"Overall RMSLE:\", \" \"*(30-len(\"Overall RMSLE\")), overall_rmsle)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not apply encoding on cluster ans store_nbr\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error\n",
    "\n",
    "# Define your variables\n",
    "cont_vars = [ 'onpromotion', 'dcoilwtico']\n",
    "encode_vars = ['city', 'state', 'type_store','type_holiday', 'locale', 'dayweek']\n",
    "other_vars = ['year','month', 'day', 'quarter' , 'weekyear', 'isweekend', 'transferred', 'store_nbr', 'cluster']\n",
    "cols = cont_vars + encode_vars + other_vars\n",
    "categories = list(df['family'].unique())\n",
    "\n",
    "\n",
    "def preprocess_train_v04(model, split_date = \"2017-01-01\"):\n",
    "\n",
    "    split_date = pd.to_datetime(split_date) \n",
    "    # Split the data\n",
    "    train_data = df[df.date< split_date]\n",
    "    test_data = df[df.date >= split_date]\n",
    "    y_hat_test_all = pd.Series(index=test_data.index) \n",
    "\n",
    "    # Create the preprocessing pipeline, we need to use the ColumnTransfer class since each transforemer will be applied on diffrent part of dataframe\n",
    "    ct = ColumnTransformer(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler(), cont_vars),\n",
    "            (\"onehot_encoder\", OneHotEncoder(), encode_vars)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Create the main pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', ct),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    print(\"RMSLE within each category\\n\", \"=\"*(50))\n",
    "    for cat in categories:\n",
    "        X_train = train_data[train_data['family']==cat][cols]\n",
    "        X_test = test_data[test_data['family']==cat][cols]\n",
    "        y_train = train_data[train_data['family']==cat]['sales']\n",
    "        y_test = test_data[test_data['family']==cat]['sales']\n",
    "        y_train_log = np.log(y_train+10)\n",
    "        y_test_log = np.log(y_test+10)\n",
    "\n",
    "        pipeline.fit(X_train, y_train_log)\n",
    "        y_hat_test = np.exp(pipeline.predict(X_test))-10\n",
    "        y_hat_test[y_hat_test<0] = 0\n",
    "        print(f\"{cat}:\", \" \"*(30-len(cat)), mean_squared_log_error(y_test, y_hat_test, squared= False))\n",
    "\n",
    "        y_hat_test_all[test_data.index[test_data['family'] == cat]] = y_hat_test\n",
    "\n",
    "    \n",
    "    # Calculate the MSLE for all categories combined\n",
    "    overall_rmsle = mean_squared_log_error(test_data['sales'], y_hat_test_all, squared= False)\n",
    "    print(\"=\"*(50))\n",
    "    print(\"Overall RMSLE:\", \" \"*(30-len(\"Overall RMSLE\")), overall_rmsle)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************ v05 *****************\n",
    "\n",
    "# Modification of v04\n",
    "# Do not consider 'quarter' and 'weakyear' and 'isweekend'\n",
    "# (v04: Do not apply encoding on cluster ans store_nbr)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error\n",
    "\n",
    "# Define your variables\n",
    "cont_vars = [ 'onpromotion', 'dcoilwtico']\n",
    "encode_vars = ['city', 'state', 'type_store','type_holiday', 'locale', 'dayweek']\n",
    "other_vars = ['year','month', 'day', 'store_nbr', 'cluster','transferred']\n",
    "cols = cont_vars +encode_vars + other_vars\n",
    "categories = list(df['family'].unique())\n",
    "\n",
    "\n",
    "def preprocess_train_v05(model, split_date = \"2017-01-01\"):\n",
    "\n",
    "    split_date = pd.to_datetime(split_date) \n",
    "    # Split the data\n",
    "    train_data = df[df.date< split_date]\n",
    "    test_data = df[df.date >= split_date]\n",
    "    y_hat_test_all = pd.Series(index=test_data.index) \n",
    "\n",
    "    # Create the preprocessing pipeline, we need to use the ColumnTransfer class since each transforemer will be applied on diffrent part of dataframe\n",
    "    ct = ColumnTransformer(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler(), cont_vars),\n",
    "            (\"onehot_encoder\", OneHotEncoder(), encode_vars)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Create the main pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', ct),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    print(\"RMSLE within each category\\n\", \"=\"*(50))\n",
    "    for cat in categories:\n",
    "        X_train = train_data[train_data['family']==cat][cols]\n",
    "        X_test = test_data[test_data['family']==cat][cols]\n",
    "        y_train = train_data[train_data['family']==cat]['sales']\n",
    "        y_test = test_data[test_data['family']==cat]['sales']\n",
    "        y_train_log = np.log(y_train+10)\n",
    "        y_test_log = np.log(y_test+10)\n",
    "\n",
    "        pipeline.fit(X_train, y_train_log)\n",
    "        y_hat_test = np.exp(pipeline.predict(X_test))-10\n",
    "        y_hat_test[y_hat_test<0] = 0\n",
    "        print(f\"{cat}:\", \" \"*(30-len(cat)), mean_squared_log_error(y_test, y_hat_test, squared= False))\n",
    "\n",
    "        y_hat_test_all[test_data.index[test_data['family'] == cat]] = y_hat_test\n",
    "\n",
    "    \n",
    "    # Calculate the MSLE for all categories combined\n",
    "    overall_rmsle = mean_squared_log_error(test_data['sales'], y_hat_test_all, squared= False)\n",
    "    print(\"=\"*(50))\n",
    "    print(\"Overall RMSLE:\", \" \"*(30-len(\"Overall RMSLE\")), overall_rmsle)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification of v04 and v05\n",
    "# apply scaling on : 'year','month', 'day', 'store_nbr', 'cluster'\n",
    "# (v:05)Do not consider 'quarter' and 'weakyear' and 'isweekend'\n",
    "# (v04 and v05): Do not apply encoding on cluster ans store_nbr)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error\n",
    "\n",
    "# Define your variables\n",
    "cont_vars = [ 'onpromotion', 'dcoilwtico', 'year','month', 'day', 'store_nbr', 'cluster']\n",
    "encode_vars = ['city', 'state', 'type_store','type_holiday', 'locale', 'dayweek']\n",
    "other_vars = ['transferred']\n",
    "cols = cont_vars +encode_vars + other_vars\n",
    "categories = list(df['family'].unique())\n",
    "\n",
    "\n",
    "def preprocess_train_v06(model, split_date = \"2017-01-01\"):\n",
    "\n",
    "    split_date = pd.to_datetime(split_date) \n",
    "    # Split the data\n",
    "    train_data = df[df.date< split_date]\n",
    "    test_data = df[df.date >= split_date]\n",
    "    y_hat_test_all = pd.Series(index=test_data.index) \n",
    "\n",
    "    # Create the preprocessing pipeline, we need to use the ColumnTransfer class since each transforemer will be applied on diffrent part of dataframe\n",
    "    ct = ColumnTransformer(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler(), cont_vars),\n",
    "            (\"onehot_encoder\", OneHotEncoder(), encode_vars)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Create the main pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', ct),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    print(\"RMSLE within each category\\n\", \"=\"*(50))\n",
    "    for cat in categories:\n",
    "        X_train = train_data[train_data['family']==cat][cols]\n",
    "        X_test = test_data[test_data['family']==cat][cols]\n",
    "        y_train = train_data[train_data['family']==cat]['sales']\n",
    "        y_test = test_data[test_data['family']==cat]['sales']\n",
    "        y_train_log = np.log(y_train+10)\n",
    "        y_test_log = np.log(y_test+10)\n",
    "\n",
    "        pipeline.fit(X_train, y_train_log)\n",
    "        y_hat_test = np.exp(pipeline.predict(X_test))-10\n",
    "        y_hat_test[y_hat_test<0] = 0\n",
    "        print(f\"{cat}:\", \" \"*(30-len(cat)), mean_squared_log_error(y_test, y_hat_test, squared= False))\n",
    "\n",
    "        y_hat_test_all[test_data.index[test_data['family'] == cat]] = y_hat_test\n",
    "\n",
    "    \n",
    "    # Calculate the MSLE for all categories combined\n",
    "    overall_rmsle = mean_squared_log_error(test_data['sales'], y_hat_test_all, squared= False)\n",
    "    print(\"=\"*(50))\n",
    "    print(\"Overall RMSLE:\", \" \"*(30-len(\"Overall RMSLE\")), overall_rmsle)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v07\n",
    "\n",
    "# Modification of v04 and v05\n",
    "# Do not consider  type_holiday \n",
    "#(v05: Do not consider 'quarter' and 'weakyear' and 'isweekend')\n",
    "# (v05: (v04: Do not apply encoding on cluster ans store_nbr))\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error\n",
    "\n",
    "# Define your variables\n",
    "cont_vars = [ 'onpromotion', 'dcoilwtico']\n",
    "encode_vars = ['city', 'state' , 'locale', 'dayweek', 'type_store' ]\n",
    "other_vars = ['year','month', 'day', 'store_nbr', 'cluster', 'transferred']\n",
    "cols = cont_vars +encode_vars + other_vars\n",
    "categories = list(df['family'].unique())\n",
    "\n",
    "\n",
    "def preprocess_train_v07(model, split_date = \"2017-01-01\"):\n",
    "\n",
    "    split_date = pd.to_datetime(split_date) \n",
    "    # Split the data\n",
    "    train_data = df[df.date< split_date]\n",
    "    test_data = df[df.date >= split_date]\n",
    "    y_hat_test_all = pd.Series(index=test_data.index) \n",
    "\n",
    "    # Create the preprocessing pipeline, we need to use the ColumnTransfer class since each transforemer will be applied on diffrent part of dataframe\n",
    "    ct = ColumnTransformer(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler(), cont_vars),\n",
    "            (\"onehot_encoder\", OneHotEncoder(), encode_vars)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Create the main pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', ct),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    print(\"RMSLE within each category\\n\", \"=\"*(50))\n",
    "    for cat in categories:\n",
    "        X_train = train_data[train_data['family']==cat][cols]\n",
    "        X_test = test_data[test_data['family']==cat][cols]\n",
    "        y_train = train_data[train_data['family']==cat]['sales']\n",
    "        y_test = test_data[test_data['family']==cat]['sales']\n",
    "        y_train_log = np.log(y_train+10)\n",
    "        y_test_log = np.log(y_test+10)\n",
    "\n",
    "        pipeline.fit(X_train, y_train_log)\n",
    "        y_hat_test = np.exp(pipeline.predict(X_test))-10\n",
    "        y_hat_test[y_hat_test<0] = 0\n",
    "        print(f\"{cat}:\", \" \"*(30-len(cat)), mean_squared_log_error(y_test, y_hat_test, squared= False))\n",
    "\n",
    "        y_hat_test_all[test_data.index[test_data['family'] == cat]] = y_hat_test\n",
    "\n",
    "    \n",
    "    # Calculate the MSLE for all categories combined\n",
    "    overall_rmsle = mean_squared_log_error(test_data['sales'], y_hat_test_all, squared= False)\n",
    "    print(\"=\"*(50))\n",
    "    print(\"Overall RMSLE:\", \" \"*(30-len(\"Overall RMSLE\")), overall_rmsle)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modification of v04 and v05\n",
    "# change encoding type\n",
    "#v05:\n",
    "# Do not consider 'quarter' and 'weakyear' and 'isweekend'\n",
    "# (v04: Do not apply encoding on cluster ans store_nbr)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error\n",
    "\n",
    "# Define your variables\n",
    "cont_vars = [ 'onpromotion', 'dcoilwtico']\n",
    "encode_vars = ['city', 'state', 'type_store','type_holiday', 'locale', 'dayweek']\n",
    "other_vars = ['year','month', 'day', 'store_nbr', 'cluster','transferred']\n",
    "cols = cont_vars + encode_vars + other_vars\n",
    "categories = list(df['family'].unique())\n",
    "\n",
    "\n",
    "def preprocess_train_v08(model, split_date = \"2017-01-01\"):\n",
    "\n",
    "    split_date = pd.to_datetime(split_date) \n",
    "    # Split the data\n",
    "    train_data = df[df.date< split_date]\n",
    "    test_data = df[df.date >= split_date]\n",
    "    y_hat_test_all = pd.Series(index=test_data.index) \n",
    "\n",
    "    # Create the preprocessing pipeline, we need to use the ColumnTransfer class since each transforemer will be applied on diffrent part of dataframe\n",
    "    ct = ColumnTransformer(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler(), cont_vars),\n",
    "            (\"encoder\", LabelEncoder(), encode_vars)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Create the main pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', ct),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    print(\"RMSLE within each category\\n\", \"=\"*(50))\n",
    "    for cat in categories:\n",
    "        X_train = train_data[train_data['family']==cat][cols]\n",
    "        X_test = test_data[test_data['family']==cat][cols]\n",
    "        y_train = train_data[train_data['family']==cat]['sales']\n",
    "        y_test = test_data[test_data['family']==cat]['sales']\n",
    "        y_train_log = np.log(y_train+10)\n",
    "        y_test_log = np.log(y_test+10)\n",
    "\n",
    "        pipeline.fit(X_train, y_train_log)\n",
    "        y_hat_test = np.exp(pipeline.predict(X_test))-10\n",
    "        y_hat_test[y_hat_test<0] = 0\n",
    "        print(f\"{cat}:\", \" \"*(30-len(cat)), mean_squared_log_error(y_test, y_hat_test, squared= False))\n",
    "\n",
    "        y_hat_test_all[test_data.index[test_data['family'] == cat]] = y_hat_test\n",
    "\n",
    "    \n",
    "    # Calculate the MSLE for all categories combined\n",
    "    overall_rmsle = mean_squared_log_error(test_data['sales'], y_hat_test_all, squared= False)\n",
    "    print(\"=\"*(50))\n",
    "    print(\"Overall RMSLE:\", \" \"*(30-len(\"Overall RMSLE\")), overall_rmsle)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_11136\\73027641.py:20: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.6669351956467529\n",
      "BABY CARE:                       0.33832031460662515\n",
      "BEAUTY:                          0.6472716084002237\n",
      "BEVERAGES:                       1.110922024640117\n",
      "BOOKS:                           0.32664611938149074\n",
      "BREAD/BAKERY:                    0.8907091001870384\n",
      "CELEBRATION:                     0.8034725617144592\n",
      "CLEANING:                        1.0262416684422149\n",
      "DAIRY:                           0.987129067073641\n",
      "DELI:                            0.8037509949088049\n",
      "EGGS:                            0.8722937507731852\n",
      "FROZEN FOODS:                    0.788199773633695\n",
      "GROCERY I:                       1.1943320143386043\n",
      "GROCERY II:                      0.872924742658103\n",
      "HARDWARE:                        0.6030856424033304\n",
      "HOME AND KITCHEN I:              0.7675111535260642\n",
      "HOME AND KITCHEN II:             0.7001255512831682\n",
      "HOME APPLIANCES:                 0.45093786855018936\n",
      "HOME CARE:                       0.9579202686808983\n",
      "LADIESWEAR:                      1.1352118962058502\n",
      "LAWN AND GARDEN:                 1.0231710680900048\n",
      "LINGERIE:                        0.8538369212298906\n",
      "LIQUOR,WINE,BEER:                1.223458012463761\n",
      "MAGAZINES:                       0.8613152459522605\n",
      "MEATS:                           0.8360839641656408\n",
      "PERSONAL CARE:                   0.804714233528506\n",
      "PET SUPPLIES:                    0.7593679642138847\n",
      "PLAYERS AND ELECTRONICS:         0.7366315479207766\n",
      "POULTRY:                         0.8648601406587357\n",
      "PREPARED FOODS:                  0.8025683999418293\n",
      "PRODUCE:                         1.2615826680595572\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.6838050615962666\n",
      "SEAFOOD:                         0.8310903264494892\n",
      "==================================================\n",
      "Overall RMSLE:                   0.8612412556583408\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "preprocess_train_v01(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_11136\\371139033.py:23: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.6671210316976374\n",
      "BABY CARE:                       0.3382779510580358\n",
      "BEAUTY:                          0.6475447010366043\n",
      "BEVERAGES:                       1.1111761075972384\n",
      "BOOKS:                           0.3267930526188479\n",
      "BREAD/BAKERY:                    0.8908366395686103\n",
      "CELEBRATION:                     0.8035316301635201\n",
      "CLEANING:                        1.0264938427890036\n",
      "DAIRY:                           0.9872151332054797\n",
      "DELI:                            0.8038242050277523\n",
      "EGGS:                            0.8723847398827002\n",
      "FROZEN FOODS:                    0.787739584546886\n",
      "GROCERY I:                       1.1945576727926062\n",
      "GROCERY II:                      0.872487783568732\n",
      "HARDWARE:                        0.603176870978815\n",
      "HOME AND KITCHEN I:              0.7676472794149192\n",
      "HOME AND KITCHEN II:             0.7002893660524371\n",
      "HOME APPLIANCES:                 0.4508823352221312\n",
      "HOME CARE:                       0.9574915917814871\n",
      "LADIESWEAR:                      1.1353000809611757\n",
      "LAWN AND GARDEN:                 1.023270040418529\n",
      "LINGERIE:                        0.8537618071667129\n",
      "LIQUOR,WINE,BEER:                1.2220314196460162\n",
      "MAGAZINES:                       0.8614863309043778\n",
      "MEATS:                           0.8362020884654615\n",
      "PERSONAL CARE:                   0.8047995828342306\n",
      "PET SUPPLIES:                    0.7594674411982437\n",
      "PLAYERS AND ELECTRONICS:         0.7368472734417142\n",
      "POULTRY:                         0.8649731980265665\n",
      "PREPARED FOODS:                  0.8025464666479983\n",
      "PRODUCE:                         1.2612031370345134\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.6842143050289392\n",
      "SEAFOOD:                         0.8312909954611943\n",
      "==================================================\n",
      "Overall RMSLE:                   0.8612276874769382\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "preprocess_train_v02(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_11136\\52419329.py:22: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.6786856901170848\n",
      "BABY CARE:                       0.33960182661167737\n",
      "BEAUTY:                          0.670785426852356\n",
      "BEVERAGES:                       1.080275700316932\n",
      "BOOKS:                           0.3264587028774208\n",
      "BREAD/BAKERY:                    0.8734563394552007\n",
      "CELEBRATION:                     0.830743270480932\n",
      "CLEANING:                        1.008233208372312\n",
      "DAIRY:                           0.9596566399311676\n",
      "DELI:                            0.8070561993499085\n",
      "EGGS:                            0.8427247722880498\n",
      "FROZEN FOODS:                    0.7916326445557488\n",
      "GROCERY I:                       1.1632399430508082\n",
      "GROCERY II:                      0.8949615243181247\n",
      "HARDWARE:                        0.6006578153528735\n",
      "HOME AND KITCHEN I:              0.7693407553701377\n",
      "HOME AND KITCHEN II:             0.7214435665491046\n",
      "HOME APPLIANCES:                 0.45381207038183385\n",
      "HOME CARE:                       0.9789366071556931\n",
      "LADIESWEAR:                      1.1681816769215216\n",
      "LAWN AND GARDEN:                 1.0340728277468176\n",
      "LINGERIE:                        0.8635051066107833\n",
      "LIQUOR,WINE,BEER:                1.208183132262753\n",
      "MAGAZINES:                       0.8788941093597934\n",
      "MEATS:                           0.8363994571067926\n",
      "PERSONAL CARE:                   0.7970979870735716\n",
      "PET SUPPLIES:                    0.7661529066913491\n",
      "PLAYERS AND ELECTRONICS:         0.7512199088407957\n",
      "POULTRY:                         0.8460466256377276\n",
      "PREPARED FOODS:                  0.8169374838543908\n",
      "PRODUCE:                         1.2906275455184115\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.6855495614353078\n",
      "SEAFOOD:                         0.8854193843683007\n",
      "==================================================\n",
      "Overall RMSLE:                   0.8646345641554491\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "preprocess_train_v03(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_11136\\716114841.py:22: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.6669351956467529\n",
      "BABY CARE:                       0.33832031460662515\n",
      "BEAUTY:                          0.6472716084002237\n",
      "BEVERAGES:                       1.110922024640117\n",
      "BOOKS:                           0.32664611938149074\n",
      "BREAD/BAKERY:                    0.8907091001870384\n",
      "CELEBRATION:                     0.8034725617144592\n",
      "CLEANING:                        1.0262416684422149\n",
      "DAIRY:                           0.987129067073641\n",
      "DELI:                            0.8037509949088049\n",
      "EGGS:                            0.8722937507731852\n",
      "FROZEN FOODS:                    0.788199773633695\n",
      "GROCERY I:                       1.1943320143386043\n",
      "GROCERY II:                      0.872924742658103\n",
      "HARDWARE:                        0.6030856424033304\n",
      "HOME AND KITCHEN I:              0.7675111535260642\n",
      "HOME AND KITCHEN II:             0.7001255512831682\n",
      "HOME APPLIANCES:                 0.45093786855018936\n",
      "HOME CARE:                       0.9579202686808983\n",
      "LADIESWEAR:                      1.1352118962058502\n",
      "LAWN AND GARDEN:                 1.0231710680900048\n",
      "LINGERIE:                        0.8538369212298906\n",
      "LIQUOR,WINE,BEER:                1.223458012463761\n",
      "MAGAZINES:                       0.8613152459522605\n",
      "MEATS:                           0.8360839641656408\n",
      "PERSONAL CARE:                   0.804714233528506\n",
      "PET SUPPLIES:                    0.7593679642138847\n",
      "PLAYERS AND ELECTRONICS:         0.7366315479207766\n",
      "POULTRY:                         0.8648601406587357\n",
      "PREPARED FOODS:                  0.8025683999418293\n",
      "PRODUCE:                         1.2615826680595572\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.6838050615962666\n",
      "SEAFOOD:                         0.8310903264494892\n",
      "==================================================\n",
      "Overall RMSLE:                   0.8612412556583408\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "preprocess_train_v04(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_11136\\3975919732.py:26: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.6669351956467529\n",
      "BABY CARE:                       0.33832031460662515\n",
      "BEAUTY:                          0.6472716084002237\n",
      "BEVERAGES:                       1.110922024640117\n",
      "BOOKS:                           0.32664611938149074\n",
      "BREAD/BAKERY:                    0.8907091001870384\n",
      "CELEBRATION:                     0.8034725617144592\n",
      "CLEANING:                        1.0262416684422149\n",
      "DAIRY:                           0.987129067073641\n",
      "DELI:                            0.8037509949088049\n",
      "EGGS:                            0.8722937507731852\n",
      "FROZEN FOODS:                    0.788199773633695\n",
      "GROCERY I:                       1.1943320143386043\n",
      "GROCERY II:                      0.872924742658103\n",
      "HARDWARE:                        0.6030856424033304\n",
      "HOME AND KITCHEN I:              0.7675111535260642\n",
      "HOME AND KITCHEN II:             0.7001255512831682\n",
      "HOME APPLIANCES:                 0.45093786855018936\n",
      "HOME CARE:                       0.9579202686808983\n",
      "LADIESWEAR:                      1.1352118962058502\n",
      "LAWN AND GARDEN:                 1.0231710680900048\n",
      "LINGERIE:                        0.8538369212298906\n",
      "LIQUOR,WINE,BEER:                1.223458012463761\n",
      "MAGAZINES:                       0.8613152459522605\n",
      "MEATS:                           0.8360839641656408\n",
      "PERSONAL CARE:                   0.804714233528506\n",
      "PET SUPPLIES:                    0.7593679642138847\n",
      "PLAYERS AND ELECTRONICS:         0.7366315479207766\n",
      "POULTRY:                         0.8648601406587357\n",
      "PREPARED FOODS:                  0.8025683999418293\n",
      "PRODUCE:                         1.2615826680595572\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.6838050615962666\n",
      "SEAFOOD:                         0.8310903264494892\n",
      "==================================================\n",
      "Overall RMSLE:                   0.8612412556583408\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "preprocess_train_v05(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_11136\\4281356354.py:25: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.6669351956467529\n",
      "BABY CARE:                       0.33832031460662515\n",
      "BEAUTY:                          0.6472716084002237\n",
      "BEVERAGES:                       1.110922024640117\n",
      "BOOKS:                           0.32664611938149074\n",
      "BREAD/BAKERY:                    0.8907091001870384\n",
      "CELEBRATION:                     0.8034725617144592\n",
      "CLEANING:                        1.0262416684422149\n",
      "DAIRY:                           0.987129067073641\n",
      "DELI:                            0.8037509949088049\n",
      "EGGS:                            0.8722937507731852\n",
      "FROZEN FOODS:                    0.788199773633695\n",
      "GROCERY I:                       1.1943320143386043\n",
      "GROCERY II:                      0.872924742658103\n",
      "HARDWARE:                        0.6030856424033304\n",
      "HOME AND KITCHEN I:              0.7675111535260642\n",
      "HOME AND KITCHEN II:             0.7001255512831682\n",
      "HOME APPLIANCES:                 0.45093786855018936\n",
      "HOME CARE:                       0.9579202686808983\n",
      "LADIESWEAR:                      1.1352118962058502\n",
      "LAWN AND GARDEN:                 1.0231710680900048\n",
      "LINGERIE:                        0.8538369212298906\n",
      "LIQUOR,WINE,BEER:                1.223458012463761\n",
      "MAGAZINES:                       0.8613152459522605\n",
      "MEATS:                           0.8360839641656408\n",
      "PERSONAL CARE:                   0.804714233528506\n",
      "PET SUPPLIES:                    0.7593679642138847\n",
      "PLAYERS AND ELECTRONICS:         0.7366315479207766\n",
      "POULTRY:                         0.8648601406587357\n",
      "PREPARED FOODS:                  0.8025683999418293\n",
      "PRODUCE:                         1.2615826680595572\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.6838050615962666\n",
      "SEAFOOD:                         0.8310903264494892\n",
      "==================================================\n",
      "Overall RMSLE:                   0.8612412556583408\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "preprocess_train_v06(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_11136\\3358303167.py:27: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.6669351956467529\n",
      "BABY CARE:                       0.33832031460662515\n",
      "BEAUTY:                          0.6472716084002237\n",
      "BEVERAGES:                       1.110922024640117\n",
      "BOOKS:                           0.32664611938149074\n",
      "BREAD/BAKERY:                    0.8907091001870384\n",
      "CELEBRATION:                     0.8034725617144592\n",
      "CLEANING:                        1.0262416684422149\n",
      "DAIRY:                           0.987129067073641\n",
      "DELI:                            0.8037509949088049\n",
      "EGGS:                            0.8722937507731852\n",
      "FROZEN FOODS:                    0.788199773633695\n",
      "GROCERY I:                       1.1943320143386043\n",
      "GROCERY II:                      0.872924742658103\n",
      "HARDWARE:                        0.6030856424033304\n",
      "HOME AND KITCHEN I:              0.7675111535260642\n",
      "HOME AND KITCHEN II:             0.7001255512831682\n",
      "HOME APPLIANCES:                 0.45093786855018936\n",
      "HOME CARE:                       0.9579202686808983\n",
      "LADIESWEAR:                      1.1352118962058502\n",
      "LAWN AND GARDEN:                 1.0231710680900048\n",
      "LINGERIE:                        0.8538369212298906\n",
      "LIQUOR,WINE,BEER:                1.223458012463761\n",
      "MAGAZINES:                       0.8613152459522605\n",
      "MEATS:                           0.8360839641656408\n",
      "PERSONAL CARE:                   0.804714233528506\n",
      "PET SUPPLIES:                    0.7593679642138847\n",
      "PLAYERS AND ELECTRONICS:         0.7366315479207766\n",
      "POULTRY:                         0.8648601406587357\n",
      "PREPARED FOODS:                  0.8025683999418293\n",
      "PRODUCE:                         1.2615826680595572\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.6838050615962666\n",
      "SEAFOOD:                         0.8310903264494892\n",
      "==================================================\n",
      "Overall RMSLE:                   0.8612412556583408\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "preprocess_train_v07(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_11136\\73027641.py:20: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.5908885352532536\n",
      "BABY CARE:                       0.34227234620758606\n",
      "BEAUTY:                          0.5391496644024714\n",
      "BEVERAGES:                       0.5390630417551031\n",
      "BOOKS:                           0.29416815887161757\n",
      "BREAD/BAKERY:                    0.5578030905247099\n",
      "CELEBRATION:                     0.7194502580706879\n",
      "CLEANING:                        0.44575379239171414\n",
      "DAIRY:                           0.42090311672295977\n",
      "DELI:                            0.4123416317174955\n",
      "EGGS:                            0.5977397591082554\n",
      "FROZEN FOODS:                    0.5076144466597666\n",
      "GROCERY I:                       0.45925579339514044\n",
      "GROCERY II:                      0.766675991757525\n",
      "HARDWARE:                        0.576166445699467\n",
      "HOME AND KITCHEN I:              0.652356168614581\n",
      "HOME AND KITCHEN II:             0.5643099171302952\n",
      "HOME APPLIANCES:                 0.435738148267094\n",
      "HOME CARE:                       0.6574744834393736\n",
      "LADIESWEAR:                      0.6902373063265261\n",
      "LAWN AND GARDEN:                 0.9543506378467429\n",
      "LINGERIE:                        0.7238971857796148\n",
      "LIQUOR,WINE,BEER:                0.8602845807997305\n",
      "MAGAZINES:                       0.5975513868338022\n",
      "MEATS:                           0.6478341923931747\n",
      "PERSONAL CARE:                   0.41084348604971244\n",
      "PET SUPPLIES:                    0.7206563028256318\n",
      "PLAYERS AND ELECTRONICS:         0.716044264886672\n",
      "POULTRY:                         0.7025045543082209\n",
      "PREPARED FOODS:                  0.6640583264051748\n",
      "PRODUCE:                         1.010353021653728\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.6765118218540314\n",
      "SEAFOOD:                         0.5987268562742873\n",
      "==================================================\n",
      "Overall RMSLE:                   0.62815074544531\n",
      "train time:813.4183087348938\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb = XGBRegressor(max_depth=12, \n",
    "        min_child_weight = 1,\n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        #eval_metric= 'mae',\n",
    "        n_estimators=1000,)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "preprocess_train_v01(xgb)\n",
    "end = time.time()\n",
    "print(f\"train time:{end-start}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_11136\\73027641.py:20: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.5797739448434569\n",
      "BABY CARE:                       0.3218792244149799\n",
      "BEAUTY:                          0.5365178944082964\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\solmaz\\Desktop\\Python workbook and projects\\Practicing ML and Python\\Projects\\StoreSalesForecasting\\Preproicessing and Model Training.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xgb \u001b[39m=\u001b[39m XGBRegressor(max_depth\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         min_child_weight \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         learning_rate\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         gamma \u001b[39m=\u001b[39m \u001b[39m1.5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m preprocess_train_v01(xgb)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain time:\u001b[39m\u001b[39m{\u001b[39;00mend\u001b[39m-\u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\solmaz\\Desktop\\Python workbook and projects\\Practicing ML and Python\\Projects\\StoreSalesForecasting\\Preproicessing and Model Training.ipynb Cell 33\u001b[0m in \u001b[0;36mpreprocess_train_v01\u001b[1;34m(model, split_date)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m y_train_log \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(y_train\u001b[39m+\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m y_test_log \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(y_test\u001b[39m+\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train_log)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m y_hat_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(pipeline\u001b[39m.\u001b[39mpredict(X_test))\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y120sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m y_hat_test[y_hat_test\u001b[39m<\u001b[39m\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m (\n\u001b[0;32m   1017\u001b[0m     model,\n\u001b[0;32m   1018\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1024\u001b[0m )\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1026\u001b[0m     params,\n\u001b[0;32m   1027\u001b[0m     train_dmatrix,\n\u001b[0;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1037\u001b[0m )\n\u001b[0;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=12, \n",
    "        min_child_weight = 1,\n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        #eval_metric= 'mae',\n",
    "        n_estimators=1000,\n",
    "        alpha = 1,\n",
    "        gamma = 1.5\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "preprocess_train_v01(xgb)\n",
    "end = time.time()\n",
    "print(f\"train time:{end-start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_17668\\2951376606.py:21: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.6235512391016124\n",
      "BABY CARE:                       0.3296097109400333\n",
      "BEAUTY:                          0.54864737462978\n",
      "BEVERAGES:                       0.88478320670847\n",
      "BOOKS:                           0.32809613573726626\n",
      "BREAD/BAKERY:                    0.7369035546681804\n",
      "CELEBRATION:                     0.9392652413475157\n",
      "CLEANING:                        0.7414402847856355\n",
      "DAIRY:                           0.6679373951318653\n",
      "DELI:                            0.6342919362409936\n",
      "EGGS:                            0.7685564881872687\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\solmaz\\Desktop\\Python workbook and projects\\Practicing ML and Python\\Projects\\StoreSalesForecasting\\Preproicessing and Model Training.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xgb \u001b[39m=\u001b[39m XGBRegressor(max_depth\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         min_child_weight \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         learning_rate\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         gamma \u001b[39m=\u001b[39m \u001b[39m1.5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m preprocess_train_v02(xgb)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain time:\u001b[39m\u001b[39m{\u001b[39;00mend\u001b[39m-\u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\solmaz\\Desktop\\Python workbook and projects\\Practicing ML and Python\\Projects\\StoreSalesForecasting\\Preproicessing and Model Training.ipynb Cell 23\u001b[0m in \u001b[0;36mpreprocess_train_v02\u001b[1;34m(model, split_date)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m y_train_log \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(y_train\u001b[39m+\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m y_test_log \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(y_test\u001b[39m+\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train_log)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m y_hat_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(pipeline\u001b[39m.\u001b[39mpredict(X_test))\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y124sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m y_hat_test[y_hat_test\u001b[39m<\u001b[39m\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m (\n\u001b[0;32m   1017\u001b[0m     model,\n\u001b[0;32m   1018\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1024\u001b[0m )\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1026\u001b[0m     params,\n\u001b[0;32m   1027\u001b[0m     train_dmatrix,\n\u001b[0;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1037\u001b[0m )\n\u001b[0;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=12, \n",
    "        min_child_weight = 1,\n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        #eval_metric= 'mae',\n",
    "        n_estimators=1000,\n",
    "        alpha = 1,\n",
    "        gamma = 1.5\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "preprocess_train_v02(xgb)\n",
    "end = time.time()\n",
    "print(f\"train time:{end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_17668\\1993040802.py:22: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.5831445368163105\n",
      "BABY CARE:                       0.32190845250520794\n",
      "BEAUTY:                          0.5335974118304553\n",
      "BEVERAGES:                       0.5916791682283192\n",
      "BOOKS:                           0.3058147006278013\n",
      "BREAD/BAKERY:                    0.5779982578933477\n",
      "CELEBRATION:                     0.6911547313883426\n",
      "CLEANING:                        0.49772774166627815\n",
      "DAIRY:                           0.46622801853199564\n",
      "DELI:                            0.44766519753448086\n",
      "EGGS:                            0.5992768674124305\n",
      "FROZEN FOODS:                    0.5049898122419187\n",
      "GROCERY I:                       0.5177697405926822\n",
      "GROCERY II:                      0.7703384907717272\n",
      "HARDWARE:                        0.5741222390442761\n",
      "HOME AND KITCHEN I:              0.6539918603560618\n",
      "HOME AND KITCHEN II:             0.5453940918129798\n",
      "HOME APPLIANCES:                 0.4273128044357963\n",
      "HOME CARE:                       0.7998894755718072\n",
      "LADIESWEAR:                      0.6754970729142012\n",
      "LAWN AND GARDEN:                 0.9478342655240611\n",
      "LINGERIE:                        0.7076873942228487\n",
      "LIQUOR,WINE,BEER:                0.8534224034912571\n",
      "MAGAZINES:                       0.5893182813036956\n",
      "MEATS:                           0.6498178883972406\n",
      "PERSONAL CARE:                   0.44185851939954696\n",
      "PET SUPPLIES:                    0.6943376745226302\n",
      "PLAYERS AND ELECTRONICS:         0.7142860014990483\n",
      "POULTRY:                         0.7056929431091264\n",
      "PREPARED FOODS:                  0.6585746615972401\n",
      "PRODUCE:                         1.0483446405585304\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.652786419833876\n",
      "SEAFOOD:                         0.6014008694710411\n",
      "==================================================\n",
      "Overall RMSLE:                   0.6363164816959072\n",
      "train time:664.5338702201843\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=12, \n",
    "        min_child_weight = 1,\n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        #eval_metric= 'mae',\n",
    "        n_estimators=1000,\n",
    "        alpha = 1,\n",
    "        gamma = 1.5\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "preprocess_train_v04(xgb)\n",
    "end = time.time()\n",
    "print(f\"train time:{end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_17668\\201521651.py:24: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.5797739448434569\n",
      "BABY CARE:                       0.3218792244149799\n",
      "BEAUTY:                          0.5365178944082964\n",
      "BEVERAGES:                       0.537762360256638\n",
      "BOOKS:                           0.28756043820200083\n",
      "BREAD/BAKERY:                    0.5576009038888907\n",
      "CELEBRATION:                     0.6994406225519169\n",
      "CLEANING:                        0.4507075340799367\n",
      "DAIRY:                           0.42523564263769026\n",
      "DELI:                            0.4136818759105467\n",
      "EGGS:                            0.5891842429226757\n",
      "FROZEN FOODS:                    0.5041243116501487\n",
      "GROCERY I:                       0.4593485140821199\n",
      "GROCERY II:                      0.764930920787872\n",
      "HARDWARE:                        0.5750657674893602\n",
      "HOME AND KITCHEN I:              0.6423385542635585\n",
      "HOME AND KITCHEN II:             0.5442342050416726\n",
      "HOME APPLIANCES:                 0.42877251857395604\n",
      "HOME CARE:                       0.6579256490405545\n",
      "LADIESWEAR:                      0.6853355485112667\n",
      "LAWN AND GARDEN:                 0.9318458193211575\n",
      "LINGERIE:                        0.7049379265945485\n",
      "LIQUOR,WINE,BEER:                0.8551181865984268\n",
      "MAGAZINES:                       0.5887142395611462\n",
      "MEATS:                           0.6337463967650586\n",
      "PERSONAL CARE:                   0.41601654383050535\n",
      "PET SUPPLIES:                    0.7058655056773919\n",
      "PLAYERS AND ELECTRONICS:         0.7098874714543049\n",
      "POULTRY:                         0.6912173435285228\n",
      "PREPARED FOODS:                  0.651382678392508\n",
      "PRODUCE:                         1.0016851390541799\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.6517044192595464\n",
      "SEAFOOD:                         0.5996847376876291\n",
      "==================================================\n",
      "Overall RMSLE:                   0.6200626489794778\n",
      "train time:647.4067680835724\n"
     ]
    }
   ],
   "source": [
    "## good 0\n",
    "\n",
    "xgb = XGBRegressor(max_depth=12, \n",
    "        min_child_weight = 1,\n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        #eval_metric= 'mae',\n",
    "        n_estimators=1000,\n",
    "        alpha = 1,\n",
    "        gamma = 1.5\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "preprocess_train_v05(xgb)\n",
    "end = time.time()\n",
    "print(f\"train time:{end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_17668\\201521651.py:24: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.5793842303667394\n",
      "BABY CARE:                       0.32153626145485686\n",
      "BEAUTY:                          0.5303027348325552\n",
      "BEVERAGES:                       0.3599623551777786\n",
      "BOOKS:                           0.29462671209376434\n",
      "BREAD/BAKERY:                    0.5059413884962696\n",
      "CELEBRATION:                     0.6605951613333063\n",
      "CLEANING:                        0.31888366034703747\n",
      "DAIRY:                           0.27475330718632757\n",
      "DELI:                            0.3522441694153562\n",
      "EGGS:                            0.557403267589672\n",
      "FROZEN FOODS:                    0.535568889934484\n",
      "GROCERY I:                       0.2832435044045889\n",
      "GROCERY II:                      0.7704860659046597\n",
      "HARDWARE:                        0.5750375567868675\n",
      "HOME AND KITCHEN I:              0.6376220230494329\n",
      "HOME AND KITCHEN II:             0.5679972440639717\n",
      "HOME APPLIANCES:                 0.4302002073032984\n",
      "HOME CARE:                       0.44122650007379\n",
      "LADIESWEAR:                      0.6489788188917986\n",
      "LAWN AND GARDEN:                 0.9429295272237499\n",
      "LINGERIE:                        0.7105339417491267\n",
      "LIQUOR,WINE,BEER:                0.8515838658378307\n",
      "MAGAZINES:                       0.5808194413040355\n",
      "MEATS:                           0.5848124089611139\n",
      "PERSONAL CARE:                   0.34527622758963356\n",
      "PET SUPPLIES:                    0.7016284965973493\n",
      "PLAYERS AND ELECTRONICS:         0.6649115294932701\n",
      "POULTRY:                         0.6494241192761141\n",
      "PREPARED FOODS:                  0.6366599704216002\n",
      "PRODUCE:                         0.7553050048758564\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.6565454353678406\n",
      "SEAFOOD:                         0.6045272028789739\n",
      "==================================================\n",
      "Overall RMSLE:                   0.5801953974372496\n",
      "train time:716.725284576416\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "xgb = XGBRegressor(max_depth=12, \n",
    "        min_child_weight = 1,\n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        objective = 'reg:pseudohubererror',\n",
    "        n_estimators=1000,\n",
    "        alpha = 1,\n",
    "        gamma = 1.5\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "preprocess_train_v05(xgb)\n",
    "end = time.time()\n",
    "print(f\"train time:{end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_17668\\4281356354.py:25: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.5778604524742961\n",
      "BABY CARE:                       0.3212743922655737\n",
      "BEAUTY:                          0.5331780748181097\n",
      "BEVERAGES:                       0.5695938469371041\n",
      "BOOKS:                           0.28785139512457836\n",
      "BREAD/BAKERY:                    0.5636413110737879\n",
      "CELEBRATION:                     0.720884544451348\n",
      "CLEANING:                        0.46211370097585297\n",
      "DAIRY:                           0.43549501782843025\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\solmaz\\Desktop\\Python workbook and projects\\Practicing ML and Python\\Projects\\StoreSalesForecasting\\Preproicessing and Model Training.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xgb \u001b[39m=\u001b[39m XGBRegressor(max_depth\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         min_child_weight \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         learning_rate\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         gamma \u001b[39m=\u001b[39m \u001b[39m1.5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m preprocess_train_v06(xgb)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain time:\u001b[39m\u001b[39m{\u001b[39;00mend\u001b[39m-\u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\solmaz\\Desktop\\Python workbook and projects\\Practicing ML and Python\\Projects\\StoreSalesForecasting\\Preproicessing and Model Training.ipynb Cell 35\u001b[0m in \u001b[0;36mpreprocess_train_v06\u001b[1;34m(model, split_date)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m y_train_log \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(y_train\u001b[39m+\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m y_test_log \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(y_test\u001b[39m+\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train_log)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m y_hat_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(pipeline\u001b[39m.\u001b[39mpredict(X_test))\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y141sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m y_hat_test[y_hat_test\u001b[39m<\u001b[39m\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\sklearn.py:988\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[39mwith\u001b[39;00m config_context(verbosity\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbosity):\n\u001b[0;32m    987\u001b[0m     evals_result: TrainingCallback\u001b[39m.\u001b[39mEvalsLog \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 988\u001b[0m     train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m    989\u001b[0m         missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m    990\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    991\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    992\u001b[0m         group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    993\u001b[0m         qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    994\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    995\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m    996\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[0;32m    997\u001b[0m         eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[0;32m    998\u001b[0m         sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[0;32m    999\u001b[0m         base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[0;32m   1000\u001b[0m         eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1001\u001b[0m         eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1002\u001b[0m         create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[0;32m   1003\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[0;32m   1004\u001b[0m         feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[0;32m   1005\u001b[0m     )\n\u001b[0;32m   1006\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1008\u001b[0m     \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\sklearn.py:448\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    429\u001b[0m     missing: \u001b[39mfloat\u001b[39m,\n\u001b[0;32m    430\u001b[0m     X: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    445\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[39mstr\u001b[39m]]]:\n\u001b[0;32m    446\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39m    way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m     train_dmatrix \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[0;32m    449\u001b[0m         data\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    450\u001b[0m         label\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    451\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[0;32m    452\u001b[0m         qid\u001b[39m=\u001b[39;49mqid,\n\u001b[0;32m    453\u001b[0m         weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    454\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m    455\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[0;32m    456\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[0;32m    457\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[0;32m    458\u001b[0m         feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[0;32m    459\u001b[0m         ref\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    460\u001b[0m     )\n\u001b[0;32m    462\u001b[0m     n_validation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[0;32m    464\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence:\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\sklearn.py:908\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m    907\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[39mreturn\u001b[39;00m DMatrix(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, nthread\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\core.py:743\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    741\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 743\u001b[0m handle, feature_names, feature_types \u001b[39m=\u001b[39m dispatch_data_backend(\n\u001b[0;32m    744\u001b[0m     data,\n\u001b[0;32m    745\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m    746\u001b[0m     threads\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnthread,\n\u001b[0;32m    747\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[0;32m    748\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[0;32m    749\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[0;32m    750\u001b[0m )\n\u001b[0;32m    751\u001b[0m \u001b[39massert\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m handle\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\data.py:954\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m    952\u001b[0m     _check_data_shape(data)\n\u001b[0;32m    953\u001b[0m \u001b[39mif\u001b[39;00m _is_scipy_csr(data):\n\u001b[1;32m--> 954\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_scipy_csr(data, missing, threads, feature_names, feature_types)\n\u001b[0;32m    955\u001b[0m \u001b[39mif\u001b[39;00m _is_scipy_csc(data):\n\u001b[0;32m    956\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_scipy_csc(data, missing, feature_names, feature_types)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\data.py:114\u001b[0m, in \u001b[0;36m_from_scipy_csr\u001b[1;34m(data, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    111\u001b[0m handle \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_void_p()\n\u001b[0;32m    112\u001b[0m data \u001b[39m=\u001b[39m _transform_scipy_csr(data)\n\u001b[0;32m    113\u001b[0m _check_call(\n\u001b[1;32m--> 114\u001b[0m     _LIB\u001b[39m.\u001b[39;49mXGDMatrixCreateFromCSR(\n\u001b[0;32m    115\u001b[0m         _array_interface(data\u001b[39m.\u001b[39;49mindptr),\n\u001b[0;32m    116\u001b[0m         _array_interface(data\u001b[39m.\u001b[39;49mindices),\n\u001b[0;32m    117\u001b[0m         _array_interface(data\u001b[39m.\u001b[39;49mdata),\n\u001b[0;32m    118\u001b[0m         c_bst_ulong(data\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]),\n\u001b[0;32m    119\u001b[0m         make_jcargs(missing\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m(missing), nthread\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(nthread)),\n\u001b[0;32m    120\u001b[0m         ctypes\u001b[39m.\u001b[39;49mbyref(handle),\n\u001b[0;32m    121\u001b[0m     )\n\u001b[0;32m    122\u001b[0m )\n\u001b[0;32m    123\u001b[0m \u001b[39mreturn\u001b[39;00m handle, feature_names, feature_types\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=12, \n",
    "        min_child_weight = 1,\n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        #eval_metric= 'mae',\n",
    "        n_estimators=1000,\n",
    "        alpha = 1,\n",
    "        gamma = 1.5\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "preprocess_train_v06(xgb)\n",
    "end = time.time()\n",
    "print(f\"train time:{end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_17668\\3358303167.py:27: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.5812443295168982\n",
      "BABY CARE:                       0.3216499891450972\n",
      "BEAUTY:                          0.5341301959976889\n",
      "BEVERAGES:                       0.6404741116577736\n",
      "BOOKS:                           0.28887656621835\n",
      "BREAD/BAKERY:                    0.591066131729136\n",
      "CELEBRATION:                     0.7294052815189493\n",
      "CLEANING:                        0.5266924393096498\n",
      "DAIRY:                           0.4978395916976604\n",
      "DELI:                            0.4614423501463614\n",
      "EGGS:                            0.5995318907095537\n",
      "FROZEN FOODS:                    0.5315241578422607\n",
      "GROCERY I:                       0.5572816520146946\n",
      "GROCERY II:                      0.770247151122271\n",
      "HARDWARE:                        0.573849511240421\n",
      "HOME AND KITCHEN I:              0.6503665984135555\n",
      "HOME AND KITCHEN II:             0.5554473562386402\n",
      "HOME APPLIANCES:                 0.4289639827227662\n",
      "HOME CARE:                       0.8225251590928774\n",
      "LADIESWEAR:                      0.7059475259423191\n",
      "LAWN AND GARDEN:                 0.9408428597231631\n",
      "LINGERIE:                        0.7056556311834414\n",
      "LIQUOR,WINE,BEER:                0.8629636441995084\n",
      "MAGAZINES:                       0.5933192138922895\n",
      "MEATS:                           0.6490676877451672\n",
      "PERSONAL CARE:                   0.4566094893041313\n",
      "PET SUPPLIES:                    0.7217741239469675\n",
      "PLAYERS AND ELECTRONICS:         0.7325372805249574\n",
      "POULTRY:                         0.7076985954869566\n",
      "PREPARED FOODS:                  0.6634907360151574\n",
      "PRODUCE:                         1.2299259736487074\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.653936748079536\n",
      "SEAFOOD:                         0.6027670457789871\n",
      "==================================================\n",
      "Overall RMSLE:                   0.656374379912158\n",
      "train time:610.9905207157135\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=12, \n",
    "        min_child_weight = 1,\n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        #eval_metric= 'mae',\n",
    "        n_estimators=1000,\n",
    "        alpha = 1,\n",
    "        gamma = 1.5\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "preprocess_train_v07(xgb)\n",
    "end = time.time()\n",
    "print(f\"train time:{end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_17668\\201521651.py:24: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.5811728581444301\n",
      "BABY CARE:                       0.3210188320013521\n",
      "BEAUTY:                          0.5341914824592229\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\solmaz\\Desktop\\Python workbook and projects\\Practicing ML and Python\\Projects\\StoreSalesForecasting\\Preproicessing and Model Training.ipynb Cell 39\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xgb \u001b[39m=\u001b[39m XGBRegressor(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         booster \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdart\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         max_depth\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         gamma \u001b[39m=\u001b[39m \u001b[39m1.5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m preprocess_train_v05(xgb)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain time:\u001b[39m\u001b[39m{\u001b[39;00mend\u001b[39m-\u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\solmaz\\Desktop\\Python workbook and projects\\Practicing ML and Python\\Projects\\StoreSalesForecasting\\Preproicessing and Model Training.ipynb Cell 39\u001b[0m in \u001b[0;36mpreprocess_train_v05\u001b[1;34m(model, split_date)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m y_train_log \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(y_train\u001b[39m+\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m y_test_log \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(y_test\u001b[39m+\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train_log)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m y_hat_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(pipeline\u001b[39m.\u001b[39mpredict(X_test))\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y152sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m y_hat_test[y_hat_test\u001b[39m<\u001b[39m\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m (\n\u001b[0;32m   1017\u001b[0m     model,\n\u001b[0;32m   1018\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1024\u001b[0m )\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1026\u001b[0m     params,\n\u001b[0;32m   1027\u001b[0m     train_dmatrix,\n\u001b[0;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1037\u001b[0m )\n\u001b[0;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    "        booster = 'dart',\n",
    "        max_depth=12, \n",
    "        min_child_weight = 1,\n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        #eval_metric= 'mae',\n",
    "        n_estimators=1000,\n",
    "        alpha = 1,\n",
    "        gamma = 1.5\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "preprocess_train_v05(xgb)\n",
    "end = time.time()\n",
    "print(f\"train time:{end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_17668\\3358303167.py:27: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.5793842303667394\n",
      "BABY CARE:                       0.32153626145485686\n",
      "BEAUTY:                          0.5303027348325552\n",
      "BEVERAGES:                       0.3599623551777786\n",
      "BOOKS:                           0.29462671209376434\n",
      "BREAD/BAKERY:                    0.5059413884962696\n",
      "CELEBRATION:                     0.6605951613333063\n",
      "CLEANING:                        0.31888366034703747\n",
      "DAIRY:                           0.27475330718632757\n",
      "DELI:                            0.3522441694153562\n",
      "EGGS:                            0.557403267589672\n",
      "FROZEN FOODS:                    0.535568889934484\n",
      "GROCERY I:                       0.2832435044045889\n",
      "GROCERY II:                      0.7704860659046597\n",
      "HARDWARE:                        0.5750375567868675\n",
      "HOME AND KITCHEN I:              0.6376220230494329\n",
      "HOME AND KITCHEN II:             0.5679972440639717\n",
      "HOME APPLIANCES:                 0.4302002073032984\n",
      "HOME CARE:                       0.44122650007379\n",
      "LADIESWEAR:                      0.6489788188917986\n",
      "LAWN AND GARDEN:                 0.9429295272237499\n",
      "LINGERIE:                        0.7105339417491267\n",
      "LIQUOR,WINE,BEER:                0.8515838658378307\n",
      "MAGAZINES:                       0.5808194413040355\n",
      "MEATS:                           0.5848124089611139\n",
      "PERSONAL CARE:                   0.34527622758963356\n",
      "PET SUPPLIES:                    0.7016284965973493\n",
      "PLAYERS AND ELECTRONICS:         0.6649115294932701\n",
      "POULTRY:                         0.6494241192761141\n",
      "PREPARED FOODS:                  0.6366599704216002\n",
      "PRODUCE:                         0.7553050048758564\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.6565454353678406\n",
      "SEAFOOD:                         0.6045272028789739\n",
      "==================================================\n",
      "Overall RMSLE:                   0.5801953974372496\n",
      "train time:713.7198853492737\n"
     ]
    }
   ],
   "source": [
    "## good 1\n",
    "\n",
    "xgb = XGBRegressor(max_depth=12, \n",
    "        min_child_weight = 1,\n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        objective = 'reg:pseudohubererror',\n",
    "        n_estimators=1000,\n",
    "        alpha = 1,\n",
    "        gamma = 1.5\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "preprocess_train_v07(xgb)\n",
    "end = time.time()\n",
    "print(f\"train time:{end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_17668\\3358303167.py:27: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.5795240899384702\n",
      "BABY CARE:                       0.319941403161085\n",
      "BEAUTY:                          0.5308771358381121\n",
      "BEVERAGES:                       0.3603940126111651\n",
      "BOOKS:                           0.2850915189655425\n",
      "BREAD/BAKERY:                    0.5037758858251871\n",
      "CELEBRATION:                     0.6567620174730258\n",
      "CLEANING:                        0.3234142058976469\n",
      "DAIRY:                           0.27685813493778894\n",
      "DELI:                            0.355758810895273\n",
      "EGGS:                            0.5525787309728392\n",
      "FROZEN FOODS:                    0.5415113158892415\n",
      "GROCERY I:                       0.27988099360811347\n",
      "GROCERY II:                      0.7658867928158248\n",
      "HARDWARE:                        0.5744555363516771\n",
      "HOME AND KITCHEN I:              0.6390577914741843\n",
      "HOME AND KITCHEN II:             0.5630641855251592\n",
      "HOME APPLIANCES:                 0.4285203151907868\n",
      "HOME CARE:                       0.4339114019364181\n",
      "LADIESWEAR:                      0.6478466646894607\n",
      "LAWN AND GARDEN:                 0.942480562217353\n",
      "LINGERIE:                        0.7108744210017451\n",
      "LIQUOR,WINE,BEER:                0.8541503840911657\n",
      "MAGAZINES:                       0.579195154607422\n",
      "MEATS:                           0.5846570570193529\n",
      "PERSONAL CARE:                   0.34930082417076364\n",
      "PET SUPPLIES:                    0.6965987052598486\n",
      "PLAYERS AND ELECTRONICS:         0.664908964419824\n",
      "POULTRY:                         0.650971047510521\n",
      "PREPARED FOODS:                  0.6422790210045518\n",
      "PRODUCE:                         0.7563465962153102\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.6514427677218956\n",
      "SEAFOOD:                         0.6043607544793406\n",
      "==================================================\n",
      "Overall RMSLE:                   0.5795112702619416\n",
      "train time:688.7678925991058\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "xgb = XGBRegressor(max_depth=12, \n",
    "        min_child_weight = 1,\n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        objective = 'reg:pseudohubererror',\n",
    "        n_estimators=1000,\n",
    "        alpha = 0,\n",
    "        gamma = 1.5\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "preprocess_train_v07(xgb)\n",
    "end = time.time()\n",
    "print(f\"train time:{end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_17668\\2615066622.py:26: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit_transform() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\solmaz\\Desktop\\Python workbook and projects\\Practicing ML and Python\\Projects\\StoreSalesForecasting\\Preproicessing and Model Training.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xgb \u001b[39m=\u001b[39m XGBRegressor(max_depth\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         min_child_weight \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         learning_rate\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         gamma \u001b[39m=\u001b[39m \u001b[39m1.5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m preprocess_train_v08(xgb)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain time:\u001b[39m\u001b[39m{\u001b[39;00mend\u001b[39m-\u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\solmaz\\Desktop\\Python workbook and projects\\Practicing ML and Python\\Projects\\StoreSalesForecasting\\Preproicessing and Model Training.ipynb Cell 44\u001b[0m in \u001b[0;36mpreprocess_train_v08\u001b[1;34m(model, split_date)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m y_train_log \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(y_train\u001b[39m+\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m y_test_log \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(y_test\u001b[39m+\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train_log)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m y_hat_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(pipeline\u001b[39m.\u001b[39mpredict(X_test))\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/solmaz/Desktop/Python%20workbook%20and%20projects/Practicing%20ML%20and%20Python/Projects/StoreSalesForecasting/Preproicessing%20and%20Model%20Training.ipynb#Y206sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m y_hat_test[y_hat_test\u001b[39m<\u001b[39m\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\pipeline.py:416\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \n\u001b[0;32m    392\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    415\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 416\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[0;32m    417\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\pipeline.py:370\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    368\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    369\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 370\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    371\u001b[0m     cloned_transformer,\n\u001b[0;32m    372\u001b[0m     X,\n\u001b[0;32m    373\u001b[0m     y,\n\u001b[0;32m    374\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    375\u001b[0m     message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    376\u001b[0m     message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    377\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    378\u001b[0m )\n\u001b[0;32m    379\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    949\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 950\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    951\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:743\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    741\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m--> 743\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(X, y, _fit_transform_one)\n\u001b[0;32m    745\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result:\n\u001b[0;32m    746\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:670\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    664\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m    665\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[0;32m    666\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    667\u001b[0m     )\n\u001b[0;32m    668\u001b[0m )\n\u001b[0;32m    669\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 670\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m    671\u001b[0m         delayed(func)(\n\u001b[0;32m    672\u001b[0m             transformer\u001b[39m=\u001b[39;49mclone(trans) \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m fitted \u001b[39melse\u001b[39;49;00m trans,\n\u001b[0;32m    673\u001b[0m             X\u001b[39m=\u001b[39;49m_safe_indexing(X, column, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m    674\u001b[0m             y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    675\u001b[0m             weight\u001b[39m=\u001b[39;49mweight,\n\u001b[0;32m    676\u001b[0m             message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mColumnTransformer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    677\u001b[0m             message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(name, idx, \u001b[39mlen\u001b[39;49m(transformers)),\n\u001b[0;32m    678\u001b[0m         )\n\u001b[0;32m    679\u001b[0m         \u001b[39mfor\u001b[39;49;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(transformers, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    680\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    682\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    949\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 950\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    951\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\solmaz\\anaconda3\\envs\\DS\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: fit_transform() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "xgb = XGBRegressor(max_depth=12, \n",
    "        min_child_weight = 1,\n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        objective = 'reg:pseudohubererror',\n",
    "        n_estimators=1000,\n",
    "        alpha = 0,\n",
    "        gamma = 1.5\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "preprocess_train_v08(xgb)\n",
    "end = time.time()\n",
    "print(f\"train time:{end-start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_17668\\201521651.py:24: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.7273654651217092\n",
      "BABY CARE:                       0.3370599885413166\n",
      "BEAUTY:                          0.8893385062517619\n",
      "BEVERAGES:                       1.0067629752779397\n",
      "BOOKS:                           0.3182157957681024\n",
      "BREAD/BAKERY:                    0.9236539233874613\n",
      "CELEBRATION:                     0.8949478531321957\n",
      "CLEANING:                        0.9358594484618442\n",
      "DAIRY:                           0.9353277297815673\n",
      "DELI:                            0.8165238744179747\n",
      "EGGS:                            0.9160959771866697\n",
      "FROZEN FOODS:                    0.8083948042535437\n",
      "GROCERY I:                       0.9920186654789324\n",
      "GROCERY II:                      1.0855916624215853\n",
      "HARDWARE:                        0.6364739743711829\n",
      "HOME AND KITCHEN I:              0.8416524281785381\n",
      "HOME AND KITCHEN II:             0.7916987885801599\n",
      "HOME APPLIANCES:                 0.48012130175311984\n",
      "HOME CARE:                       1.0205249307460769\n",
      "LADIESWEAR:                      1.404140820067433\n",
      "LAWN AND GARDEN:                 1.606789453688209\n",
      "LINGERIE:                        0.914715991228364\n",
      "LIQUOR,WINE,BEER:                1.107142549008078\n",
      "MAGAZINES:                       1.0034495170985083\n",
      "MEATS:                           0.9086695738040073\n",
      "PERSONAL CARE:                   0.8329872267253218\n",
      "PET SUPPLIES:                    1.0745168655331299\n",
      "PLAYERS AND ELECTRONICS:         0.89668270384739\n",
      "POULTRY:                         0.9050278516346919\n",
      "PREPARED FOODS:                  0.8218645259762076\n",
      "PRODUCE:                         1.34855833784667\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.8183861504921298\n",
      "SEAFOOD:                         1.0685026469888852\n",
      "==================================================\n",
      "Overall RMSLE:                   0.9456921838005607\n"
     ]
    }
   ],
   "source": [
    "las = Lasso(alpha = .1)\n",
    "preprocess_train_v05(las)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solmaz\\AppData\\Local\\Temp\\ipykernel_17668\\201521651.py:24: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_hat_test_all = pd.Series(index=test_data.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE within each category\n",
      " ==================================================\n",
      "AUTOMOTIVE:                      0.6678201782379335\n",
      "BABY CARE:                       0.3380262319809103\n",
      "BEAUTY:                          0.6442345194659213\n",
      "BEVERAGES:                       1.106233846036458\n",
      "BOOKS:                           0.32348772554985816\n",
      "BREAD/BAKERY:                    0.8884225609450436\n",
      "CELEBRATION:                     0.80592928165151\n",
      "CLEANING:                        1.021804519929437\n",
      "DAIRY:                           0.9831834509771745\n",
      "DELI:                            0.8017536545269759\n",
      "EGGS:                            0.8704317599733719\n",
      "FROZEN FOODS:                    0.793213595266784\n",
      "GROCERY I:                       1.1881042610626562\n",
      "GROCERY II:                      0.8904451171658151\n",
      "HARDWARE:                        0.6029942535459136\n",
      "HOME AND KITCHEN I:              0.7616358947936931\n",
      "HOME AND KITCHEN II:             0.7002597157924846\n",
      "HOME APPLIANCES:                 0.4518402013730527\n",
      "HOME CARE:                       0.9774747162932863\n",
      "LADIESWEAR:                      1.1418596362865514\n",
      "LAWN AND GARDEN:                 1.022259280324442\n",
      "LINGERIE:                        0.8574734658709838\n",
      "LIQUOR,WINE,BEER:                1.2254243225385726\n",
      "MAGAZINES:                       0.8627779890364358\n",
      "MEATS:                           0.8321565161047518\n",
      "PERSONAL CARE:                   0.8021098416571706\n",
      "PET SUPPLIES:                    0.7607527726409518\n",
      "PLAYERS AND ELECTRONICS:         0.7353285868593584\n",
      "POULTRY:                         0.8608916363666901\n",
      "PREPARED FOODS:                  0.8012225115878499\n",
      "PRODUCE:                         1.2826288727296073\n",
      "SCHOOL AND OFFICE SUPPLIES:      0.6949732604767817\n",
      "SEAFOOD:                         0.8301888866137249\n",
      "==================================================\n",
      "Overall RMSLE:                   0.8628169592129225\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha = 10)\n",
    "preprocess_train_v05(ridge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
